{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNITPmtlw9Tq39E+NNfE6Ga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m10k1/ml-learn/blob/main/PaliGemma%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UNCVCG1Y_VZd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "必要なライブラリを読み込みます。\n",
        "* torch\n",
        "* immutabledict\n",
        "* sentencepiece\n",
        "\n"
      ],
      "metadata": {
        "id": "EOXbChidtuwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub --upgrade"
      ],
      "metadata": {
        "id": "16NUIxm-U_Kw",
        "outputId": "564c1dcb-6775-46e7-d1f2-0a9c3d8fa8e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Collecting kagglehub\n",
            "  Downloading kagglehub-0.3.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.12.14)\n",
            "Downloading kagglehub-0.3.6-py3-none-any.whl (51 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kagglehub\n",
            "  Attempting uninstall: kagglehub\n",
            "    Found existing installation: kagglehub 0.3.5\n",
            "    Uninstalling kagglehub-0.3.5:\n",
            "      Successfully uninstalled kagglehub-0.3.5\n",
            "Successfully installed kagglehub-0.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U immutabledict sentencepiece"
      ],
      "metadata": {
        "id": "0zQycxO4thCl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/google/gemma_pytorch.git"
      ],
      "metadata": {
        "id": "YUJOakHEJUjH",
        "outputId": "b42f5167-7a48-41c0-99b8-06ca362ff4ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gemma_pytorch'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 239 (delta 86), reused 53 (delta 53), pack-reused 121 (from 2)\u001b[K\n",
            "Receiving objects: 100% (239/239), 2.18 MiB | 17.16 MiB/s, done.\n",
            "Resolving deltas: 100% (135/135), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/gemma/\n",
        "!mv /content/gemma_pytorch/gemma/* /content/gemma/\n"
      ],
      "metadata": {
        "id": "DwWoMRhVJnZ2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import shutil\n",
        "sys.path.append(\"/content/gemma_pytorch/\")\n",
        "from gemma.config import GemmaConfig, get_model_config\n",
        "from gemma.model import GemmaForCausalLM\n",
        "from gemma.tokenizer import Tokenizer\n",
        "import contextlib\n",
        "import os\n",
        "import torch\n",
        "import kagglehub"
      ],
      "metadata": {
        "id": "M9knPs5tKMux"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "VARIANT = \"2b-v2\"\n",
        "MACHINE_TYPE = \"cuda\"\n",
        "model_path = kagglehub.model_download('google/gemma-2-2b-jpn-it/pyTorch/gemma-2-2b-jpn-it')\n",
        "\n",
        "dest_dir = \"/content/gemma/gemma-2-2b-jpn-it/pytorch/gemma-2-2b-jpn-it/1/\"\n",
        "\n",
        "if not os.path.exists(dest_dir):\n",
        "  os.makedirs(dest_dir)\n",
        "\n",
        "model_weights_path = os.path.join(dest_dir, \"model.ckpt\")\n",
        "shutil.copy(os.path.join(model_path, \"model.ckpt\"), model_weights_path)\n",
        "\n",
        "model_tokenizer_path = os.path.join(dest_dir, \"tokenizer.model\")\n",
        "shutil.copy(os.path.join(model_path, \"tokenizer.model\"), model_tokenizer_path)\n"
      ],
      "metadata": {
        "id": "HYthBkdOKVID",
        "outputId": "3ecca891-f7fe-4a7a-9f13-3c85f6ea05db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gemma/gemma-2-2b-jpn-it/pytorch/gemma-2-2b-jpn-it/1/tokenizer.model'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@contextlib.contextmanager\n",
        "def _set_default_tensor_type(dtype: torch.dtype):\n",
        "  \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
        "  torch.set_default_dtype(dtype)\n",
        "  yield\n",
        "  torch.set_default_dtype(torch.float)\n",
        "\n",
        "model_config = get_model_config(VARIANT)\n",
        "model_config.tokenizer = model_tokenizer_path\n",
        "\n",
        "device = torch.device(MACHINE_TYPE)\n",
        "with _set_default_tensor_type(model_config.get_dtype()):\n",
        "  model = GemmaForCausalLM(model_config)\n",
        "  model.load_weights(model_weights_path)\n",
        "  model = model.to(device).eval()"
      ],
      "metadata": {
        "id": "046Fr9RLKYWF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the model\n",
        "USER_CHAT_TEMPLATE = \"<start_of_turn>user\\n{prompt}<end_of_turn>\\n\"\n",
        "\n",
        "prompt = (\n",
        "  USER_CHAT_TEMPLATE.format(\n",
        "    prompt=\"「おにぎり」をテーマに短編を書いてください\"\n",
        "  )\n",
        "  + \"<start_of_turn>model\\n\"\n",
        ")\n",
        "print(prompt)\n",
        "\n",
        "result = model.generate(\n",
        "  prompt,\n",
        "  device=device,\n",
        "  output_len=256,\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "jv45M67HgVsj",
        "outputId": "7bae195a-ffdb-416e-feed-e78f54f9dc52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start_of_turn>user\n",
            "「おにぎり」をテーマに短編を書いてください<end_of_turn>\n",
            "<start_of_turn>model\n",
            "\n",
            "## おにぎりの物語\n",
            "\n",
            "春風に誘われるように、お寺の門前に佇む小さな店。その暖簾には、息づく「おにぎり」への想いが込める。\n",
            "\n",
            "「あきら」は、長い時間をかけて培ってきた技。手際の良い握り、鮭の甘味、ご飯の炊き具合。すべて、家族の温もり、故郷の記憶、そして日常を忘れさせる、優しい味へのこだわりで紡がれていく。\n",
            "\n",
            "ある日、その店に訪れたのは、疲れた心を持つ青年。「元気になりましょう」と店主は言った。青年の心が閉ざされていた。それは、故郷の忘れ去られた夢、そして将来への不安だった。\n",
            "\n",
            "「おにぎり」は単なる食物ではなく、その形、その温度、その香りは、人生のあらゆる局面に寄り添う。\n",
            "\n",
            "店主は、青年の前に「人生は、ただ一つのおにぎりと同じように、小さな形でも、温かい味でいっぱいのものです。」と言った。\n",
            "\n",
            "青年は、初めて深く「おにぎり」を味わった。温まった匂いと、ご飯の香ばしさが、彼の人生を揺さぶった。\n",
            "\n",
            "その日から、青年は再び、自身の夢に向かって歩き\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "パラメータをダウンロードします。"
      ],
      "metadata": {
        "id": "mnpJ2uD7uUEJ"
      }
    }
  ]
}